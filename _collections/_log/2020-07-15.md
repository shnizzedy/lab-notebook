---
projects: [c-pac, c-pac-on-habanero, nmind, knowb4]
author: [Jon Clucas]
date: 2020-07-15
---

- [ ] :construction: C-PAC v1.7.0
   - [x] C-PAC longitudinal testing
   - [ ] C-PAC {% octicon issue-opened height:12 class:"right left" aria-label:issue %} \#1260
      - [x] reopened [{% octicon issue-opened height:12 class:"right left" aria-label:issue %} FCP-INDI/C-PAC#1260](https://github.com/FCP-INDI/C-PAC/issues/1260)
      - [x] opened draft [{% octicon git-pull-request height:12 class:"right left" aria-label:PR %} FCP-INDI/C-PAC#1326](https://github.com/FCP-INDI/C-PAC/pull/1326)
   - [x] C-PAC reg-test-1
- [x] C-PAC on Habanero â€• [![Slack](https://cdn.brandfolder.io/5H442O3W/at/pl546j-7le8zk-6gwiyo/Slack_Mark.png?width=12&height=12)](https://cmi-cnl.slack.com/archives/GC8KKE490/p1594821845216700)
- [x] NMIND coding standards meeting
- [ ] KnowB4 (:calendar: due September 30)

<!--more--> 

### didn't get to

- [ ] C-PAC Python package v0.2.5
- [ ] simplify automated testing (C-PAC)
- [ ] spec Docker image for testing
- [ ] C-PAC ANTS priors testing
- [ ]
   ```Python
   requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http+docker://localhost/v1.35/containers/f613e7a80272cc015bc1e92a8c16a4c0e73bc3df98988c79a8a3c0df4f7be207/start
 docker.errors.APIError: 500 Server Error: Internal Server Error ("OCI runtime create failed: container_linux.go:348: starting container process caused 
 ```
   on Ned

### C-PAC longitudinal testing
* Shared [ðŸ“Ž working/anat_longitudinal_template_0027234_subject_specific_anat_template_fsl_skullstrip_0027234__report_report.rst]() with Xinhui
* Created new [data_config_2020-07-15.yml](https://github.com/shnizzedy/lab-notebook/blob/gh-pages/assets/log_attachments/2020-07-15/data_config_2020-07-15.yml) & [2020-07-15_feature-longitudinal_9fb6498_test-run.sh](https://github.com/shnizzedy/lab-notebook/tree/gh-pages/assets/log_attachments/2020-07-15/2020-07-15_feature-longitudinal_9fb6498_test-run.sh) <sup><a href="#longitudinal-error-1">[1]</a></sup>
* Another [data_config_2020-07-15.yml](https://github.com/shnizzedy/lab-notebook/blob/gh-pages/assets/log_attachments/2020-07-15/data_config_2020-07-15.1.yml) <sup><a href="#longitudinal-error-2">[2]</a></sup>
* Review [data_config_sub-0027224.yml](https://github.com/shnizzedy/lab-notebook/tree/gh-pages/assets/log_attachments/2020-07-15/data_config_sub-0027224.yml) from Xinhui ([![Slack](https://cdn.brandfolder.io/5H442O3W/at/pl546j-7le8zk-6gwiyo/Slack_Mark.png?width=12&height=12) July 13](https://cmi-cnl.slack.com/archives/GC8KKE490/p1594650367122200))
   * figured it out. one entry per __session__ not per __subject__.
   * created another new [data_config_2020-07-15.yml](https://github.com/shnizzedy/lab-notebook/blob/gh-pages/assets/log_attachments/2020-07-15/data_config_2020-07-15.2.yml)
   * running now
   * [![Slack](https://cdn.brandfolder.io/5H442O3W/at/pl546j-7le8zk-6gwiyo/Slack_Mark.png?width=12&height=12)                                                                                                                                                                                                                     ](https://cmi-cnl.slack.com/archives/GC8KKE490/p1594828892224100)
   <table class="conversation"><tr><td>Jon</td><td markdown="1">
   Alright, I figured out where I went wrong. Now it's running well.
   
   What didn't work:

   * One anat scan per subject as a string
   * One or more anat scans per subject in a list
   * One or more anat scans per subject in a dict
  
   What did work:
   
   * More than one session dict per subject
   
   I doubt I'll be alone in making the mistakes I made, so I vote we catch those mistakes and point to documentation of how to write a data config for longitudinal-anat
   </td></tr><tr><td>Xinhui</td><td markdown="1">
   Data config docs is a great idea. I updated the code and now I am testing only one anat scan case, I try to keep the longitudinal running for single session, to generate identical longitudinal template as that anat scan, considering there may be a case where some subjects have multiple sessions and some only have one, and the user just used one config for all subjects. But I also feel it's pointless to run longitudinal on single session.. let me know if you have better design idea
   </td></tr><tr><td>Jon</td><td markdown="1">
   I don't know how complicated it would be to implement, but I think it would make sense to skip longitundinal for single session even if longitudinal is turned on. If longitudinal is on and some subjects have multiple sessions and others don't, it does longitudinal on the ones that have multiple sessions and skips it for those that just have one.
   </td></tr></table>

#### errors
<span name="longitudinal-error-1">1.</span>
   ```Python
The 'in_file' trait of a RefitInputSpec instance must be an existing file name, but a value of {'anat_run-1': {'scan': '/media/ebs/data/IBATRT/IBA_TRT/0027234/session_1/anat_1/anat.nii.gz'}, 'anat_run-2': {'scan': '/media/ebs/data/IBATRT/IBA_TRT/0027234/session_1/anat_1/anat.nii.gz'}} <class 'dict'> was specified.
```
   
<span name="longitudinal-error-2">2.</span>   
   ```Python
AttributeError: 'list' object has no attribute 'lower'
```

<span name="longitudinal-error-3">3.</span>  
   ```Python
Longitudinal pipeline completed.
200715-17:45:06,474 nipype.workflow INFO:
   C-PAC version: 1.6.2
   Setting maximum number of cores per participant to 3
   Setting number of participants at once to 1
   Setting OMP_NUM_THREADS to 1
   Setting MKL_NUM_THREADS to 1
   Setting ANTS/ITK thread usage to 3
   Maximum potential number of cores that might be used during this run: 3
No node for output: anatomical_brain
Traceback (most recent call last):
 File "/code/run.py", line 606, in <module>
   test_config = 1 if args.analysis_level == "test_config" else 0
 File "/code/CPAC/pipeline/cpac_runner.py", line 519, in run
   p_name, plugin, plugin_args, test_config)
 File "/code/CPAC/pipeline/cpac_pipeline.py", line 319, in run_workflow
   subject_id, sub_dict, c, p_name, num_ants_cores
 File "/code/CPAC/pipeline/cpac_pipeline.py", line 1629, in build_workflow
   workflow, strat_list, diff_complete = connect_func_to_anat_init_reg(workflow, strat_list, c)
 File "/code/CPAC/registration/registration.py", line 982, in connect_func_to_anat_init_reg
   node, out_file = strat['anatomical_brain']
 File "/code/CPAC/utils/strategy.py", line 60, in __getitem__
   return self.resource_pool[resource_key]
KeyError: 'anatomical_brain'
```

* 2020-07-15_feature-longitudinal_9fb6498_test-run.sh
* 2020-07-15_feature-longitudinal_9fb6498_test-run_clean_outputs.sh

### C-PAC {% octicon issue-opened height:12 class:"right left" aria-label:issue %} \#1260

* reopened [{% octicon issue-opened height:12 class:"right left" aria-label:issue %} FCP-INDI/C-PAC#1260](https://github.com/FCP-INDI/C-PAC/issues/1260)
* opened draft [{% octicon git-pull-request height:12 class:"right left" aria-label:PR %} FCP-INDI/C-PAC#1326](https://github.com/FCP-INDI/C-PAC/pull/1326)

### C-PAC regtest-1
* 2020-07-15_regtest-1.fixSameFileError.sh
* 2020-07-15_regtest-1.sh

### C-PAC on Habanero
[![Slack](https://cdn.brandfolder.io/5H442O3W/at/pl546j-7le8zk-6gwiyo/Slack_Mark.png?width=12&height=12)](https://cmi-cnl.slack.com/archives/GC8KKE490/p1594821845216700)

<table class="conversation"><tr><td>Jon</td>
<td markdown="1">
Not necessarily 1.7.0-related, but for our Columbia colleagues, a subject that is allegedly "less motion" is getting almost completely censored (155 timepoints out of 180):

```Python
RuntimeError: Command:
3dTproject -input /out/working/resting_preproc_sub-151_sub-151/nuisance_regression_before-filt_2_0/_scan_rest/_selector_WM-2mmE-M_CSF-2mmE-M_aC-CSF+WM-2mm-DPC5_M-SDB_P-2_BP-B0.009-T0.08_C-I-1+2-FD-P0.3/nuisance_regression/sub-151_ses-1_task-rest_run-1_bold_calc_tshift_resample_volreg_calc_maths.nii.gz -cenmode NTRP -censor /out/working/resting_preproc_sub-151_sub-151/nuisance_regression_before-filt_2_0/_scan_rest/find_offending_time_points/censors.tsv -mask /out/working/resting_preproc_sub-151_sub-151/func_preproc_afni_mean_3dvolreg_0/func_preproc_afni_mean_3dvolreg_0_skullstrip/_scan_rest/func_get_brain_mask_AFNI/sub-151_ses-1_task-rest_run-1_bold_calc_tshift_resample_volreg_mask.nii.gz -ort /out/working/resting_preproc_sub-151_sub-151/nuisance_regressor_2_0/_scan_rest/_selector_WM-2mmE-M_CSF-2mmE-M_aC-CSF+WM-2mm-DPC5_M-SDB_P-2_BP-B0.009-T0.08_C-I-1+2-FD-P0.3/build_nuisance_regressors/nuisance_regressors.1D -polort 2 -prefix residuals.nii.gz
Standard output:
Standard error:
++ 3dTproject: AFNI version=AFNI_20.1.17 (Jun 20 2020) [64-bit]
++ Authored by: Cox the Algebraic (Linear)
++ input time points = 180 ; censored = 155 ; remaining = 25
++ Setting up regressors
++ 1 Blocks * 3 polynomials -- 3 polort regressors
 + -- 31 other fixed ort regressors
** ERROR: total number of fixed regressors (34) is too many for 25 retained time points!
** FATAL ERROR: Cannot continue after above errors :-( :-( :-( !!
** Program compile date = Jun 20 2020
Return code: 1
```

Any ideas why?
</td></tr><tr><td>Steve</td><td markdown="1">
do you have the FD_P/FD_J, and the threshold they picked?
</td></tr><tr><td>Jon</td><td markdown="1">

```YAML
Censor:
   method: SpikeRegression
   thresholds: 
      - type: FD_P
        value: 0.5
   number_of_previous_trs_to_censor: 1
   number_of_subsequent_trs_to_censor: 2
```

```YAML
Censor:
   method: Interpolate
   thresholds: 
      - type: FD_P
        value: 0.5
   number_of_previous_trs_to_censor: 1
   number_of_subsequent_trs_to_censor: 2
```

They've got 3 strategies, one with spike and two with interpolate. The whole pipeline config is here if that's helpful


</td></tr><tr><td>Steve</td><td markdown="1">
thanks! do you also have their FD_P 1D file?
</td></tr><tr><td>Jon</td><td markdown="1">
no, but I can get it
</td></tr></table>
    
### NMIND

#### coding standards meeting

* fork [<img src="https://hackmd.io/favicon.png" alt="HackMD" style="height:1em;"> Zen of DCAN](https://hackmd.io/Wss5GexWSq6vYOk-KEKswQ?view#Documentation)
* suggest VSCode
* version control doc

### KnowB4

* Cyber Heroes Series
   * Introduction
   * Don't Take the Bait
   * Mobile Mayhem